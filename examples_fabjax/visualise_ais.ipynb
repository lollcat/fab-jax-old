{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise AIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fab.sampling_methods.annealed_importance_sampling import AnnealedImportanceSampler\n",
    "from fab.target_distributions.gmm import GMM\n",
    "from fab.types_ import HaikuDistribution\n",
    "from fab.utils.plotting import plot_marginal_pair\n",
    "from fab.sampling_methods.mcmc.hamiltonean_monte_carlo import HMCStatePAccept\n",
    "import haiku as hk\n",
    "import distrax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2\n",
    "batch_size = 512\n",
    "rng = hk.PRNGSequence(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Gaussian Learnt Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gaussian_base_dist(event_shape = (dim, ), dtype = jnp.float32):\n",
    "    loc = hk.get_parameter(\"loc\", shape=event_shape, init=jnp.zeros, dtype=dtype)\n",
    "    log_scale = hk.get_parameter(\"log_scale\", shape=event_shape, init=jnp.zeros, dtype=dtype)\n",
    "    scale = jnp.exp(log_scale)\n",
    "    base_dist = distrax.Independent(\n",
    "        distrax.Normal(\n",
    "            loc=loc,\n",
    "            scale=scale),\n",
    "        reinterpreted_batch_ndims=len(event_shape))\n",
    "    return base_dist\n",
    "\n",
    "get_model = lambda: make_gaussian_base_dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@hk.without_apply_rng\n",
    "@hk.transform\n",
    "def log_prob(data):\n",
    "    model = get_model()\n",
    "    return model.log_prob(data)\n",
    "\n",
    "@hk.transform\n",
    "def sample_and_log_prob(sample_shape):\n",
    "    model = get_model()\n",
    "    return model.sample_and_log_prob(seed=hk.next_rng_key(), sample_shape=sample_shape)\n",
    "\n",
    "\n",
    "@hk.transform\n",
    "def sample(sample_shape):\n",
    "    model = get_model()\n",
    "    return model.sample(seed=hk.next_rng_key(), sample_shape=sample_shape)\n",
    "\n",
    "learnt_distribution = HaikuDistribution(dim, log_prob, sample_and_log_prob, sample)\n",
    "samples = jnp.ones(dim)\n",
    "learnt_distribution_params = learnt_distribution.log_prob.init(jax.random.PRNGKey(0), samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = learnt_distribution.sample.apply(\n",
    "    learnt_distribution_params,\n",
    "    jax.random.PRNGKey(0), (500,))\n",
    "plot_marginal_pair(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define target distribution (GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = GMM(dim, n_mixes=5, loc_scaling=2, log_var_scaling=-2.0)\n",
    "target_log_prob = target.log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = target.sample(seed=jax.random.PRNGKey(0), sample_shape=(500,))\n",
    "plot_marginal_pair(samples, bounds=(-10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get AIS up and running. Check that thinnging samples by log weights works. \n",
    "With 5> intermediate AIS distributions, the samples look great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intermediate_distributions = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIS = AnnealedImportanceSampler(\n",
    "             learnt_distribution=learnt_distribution,\n",
    "             target_log_prob=target_log_prob,\n",
    "             n_parallel_runs=batch_size,\n",
    "             n_intermediate_distributions=n_intermediate_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_operator_state = AIS.transition_operator_manager.get_init_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_operator_state = HMCStatePAccept(\n",
    "    no_grad_params=transition_operator_state.no_grad_params,\n",
    "    step_size_params=jnp.ones_like(transition_operator_state.step_size_params)*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new, log_w, _trans_state, info = AIS.run(next(rng), learnt_distribution_params, transition_operator_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_samples = learnt_distribution.sample.apply(\n",
    "    learnt_distribution_params,\n",
    "    jax.random.PRNGKey(0), (batch_size,))\n",
    "plot_marginal_pair(base_samples)\n",
    "plot_marginal_pair(x_new, bounds=(-10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indxs = jax.random.choice(next(rng), log_w.shape[0], shape=(batch_size,), replace=True, p=jax.nn.softmax(log_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_marginal_pair(x_new[indxs], bounds=(-10, 10)) # looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise effective sample size trend for number of AIS distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(n_intermediate_distributions):\n",
    "    AIS = AnnealedImportanceSampler(\n",
    "             learnt_distribution=learnt_distribution,\n",
    "             target_log_prob=target_log_prob,\n",
    "             n_parallel_runs=batch_size,\n",
    "             n_intermediate_distributions=n_intermediate_distributions)\n",
    "    transition_operator_state = AIS.transition_operator_manager.get_init_state()\n",
    "    transition_operator_state = HMCStatePAccept(\n",
    "    no_grad_params=transition_operator_state.no_grad_params,\n",
    "    step_size_params=jnp.ones_like(transition_operator_state.step_size_params)*0.1)\n",
    "    x_new, log_w, _trans_state, info = AIS.run(next(rng), learnt_distribution_params, transition_operator_state)\n",
    "    ess = info[\"ess_ais\"]\n",
    "    return ess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais_dist_range = [1,2,4,8,16, 32]\n",
    "ess_hist = []\n",
    "for n_intermediate_distributions in ais_dist_range:\n",
    "    ess = run(n_intermediate_distributions)\n",
    "    ess_hist.append(ess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ais_dist_range, ess_hist)\n",
    "plt.xlabel(\"n ais distributions\")\n",
    "plt.ylabel(\"effective sample size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}